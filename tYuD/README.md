Thank you for recognizing the innovation and clarity of RLPO, as well as its contribution to improving the efficiency and generalizability of concept-based explanation methods. We also appreciate your valuable feedback on areas requiring clarification, which we will address comprehensively in the revised version.

### Weakness 1

We acknowledge that some sections, such as the algorithm explanation and mathematical proofs, may appear overly lengthy. To address this, we plan to streamline these sections in the final version by:
- Providing concise summaries alongside detailed explanations to improve accessibility for readers. 
- Moving some of the more intricate details (e.g., mathematical derivations) to the appendix, ensuring the main text remains reader-friendly while preserving the rigor.

We believe this restructuring will make the algorithm and proofs more digestible without compromising their completeness.

### Weakness 2

Given the page limit we were not able to include all the details on the sentiment analysis experiment in the main paper. We have added additional explanation for our experiment on sentiment analysis tasks in the Appendix D.4. We will highlight it in the main paper.

### Weakness 3

We appreciate your feedback regarding the inconsistent use of terms like “concept generation” and “concept extraction.” We will fix these in the revised paper.
